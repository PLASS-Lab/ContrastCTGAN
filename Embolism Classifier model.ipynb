{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training and validation (RSNA dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision.models import VGG16_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed \n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "class PulmonaryEmbolismDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, window_center, window_width, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.window_center = window_center\n",
    "        self.window_width = window_width\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_uid = self.data_frame.iloc[idx]['StudyInstanceUID']\n",
    "        series_uid = self.data_frame.iloc[idx]['SeriesInstanceUID']\n",
    "        sop_uid = self.data_frame.iloc[idx]['SOPInstanceUID']\n",
    "        file_path = os.path.join(self.root_dir, study_uid, series_uid, f\"{sop_uid}.dcm\")\n",
    "        dicom_image, _ = self.load_and_process_dicom(file_path)\n",
    "        if self.transform:\n",
    "            dicom_image = self.transform(dicom_image)\n",
    "        label = self.data_frame.iloc[idx]['pe_present_on_image']\n",
    "        return dicom_image, label, file_path\n",
    "\n",
    "    def load_and_process_dicom(self, dicom_file):\n",
    "        ds = pydicom.dcmread(dicom_file)\n",
    "        image = ds.pixel_array\n",
    "        if \"RescaleIntercept\" in ds and \"RescaleSlope\" in ds:\n",
    "            intercept = ds.RescaleIntercept\n",
    "            slope = ds.RescaleSlope\n",
    "            hu_image = self.convert_to_hounsfield_units(image, intercept, slope)\n",
    "        else:\n",
    "            hu_image = image.astype(np.int16)\n",
    "        windowed_image = self.apply_windowing_correctly(hu_image, self.window_center, self.window_width)\n",
    "        resized_image = Image.fromarray(windowed_image).resize((224, 224))\n",
    "        image_tensor = torch.tensor(np.array(resized_image), dtype=torch.float32).unsqueeze(0)\n",
    "        image_tensor = image_tensor.repeat(3, 1, 1)  \n",
    "        image_tensor = image_tensor / 255.0  \n",
    "        return image_tensor, hu_image\n",
    "\n",
    "    def apply_windowing_correctly(self, image, window_center, window_width):\n",
    "        window_min = window_center - window_width / 2\n",
    "        window_max = window_center + window_width / 2\n",
    "        windowed_image = np.clip(image, window_min, window_max)\n",
    "        return ((windowed_image - window_min) / (window_max - window_min) * 255).astype(np.uint8)\n",
    "\n",
    "    def convert_to_hounsfield_units(self, image, intercept, slope):\n",
    "        return image * slope + intercept\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([])  # No transformation\n",
    "\n",
    "# Load the dataset\n",
    "csv_file = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/RSNA dataset/rsna-str-pulmonary-embolism-detection/train_processed.csv'\n",
    "root_dir = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/RSNA dataset/rsna-str-pulmonary-embolism-detection/train'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Sample the dataset\n",
    "sampled_df = df.groupby('StudyInstanceUID').apply(lambda x: x.sample(frac=0.1, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Split the sampled dataset by StudyInstanceUID to avoid data leakage\n",
    "unique_studies = sampled_df['StudyInstanceUID'].unique()\n",
    "train_studies, temp_studies = train_test_split(unique_studies, test_size=0.2, random_state=42)\n",
    "val_studies, test_studies = train_test_split(temp_studies, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = sampled_df[sampled_df['StudyInstanceUID'].isin(train_studies)].reset_index(drop=True)\n",
    "val_df = sampled_df[sampled_df['StudyInstanceUID'].isin(val_studies)].reset_index(drop=True)\n",
    "test_df = sampled_df[sampled_df['StudyInstanceUID'].isin(test_studies)].reset_index(drop=True)\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = PulmonaryEmbolismDataset(train_df, root_dir, window_center=40, window_width=400, transform=transform)\n",
    "val_dataset = PulmonaryEmbolismDataset(val_df, root_dir, window_center=40, window_width=400, transform=transform)\n",
    "test_dataset = PulmonaryEmbolismDataset(test_df, root_dir, window_center=40, window_width=400, transform=transform)\n",
    "\n",
    "# Calculate the percentage of pe_label=1 in each dataset\n",
    "train_pe_label_percent = (train_df['pe_present_on_image'].mean()) * 100\n",
    "val_pe_label_percent = (val_df['pe_present_on_image'].mean()) * 100\n",
    "test_pe_label_percent = (test_df['pe_present_on_image'].mean()) * 100\n",
    "\n",
    "print(f\"Train dataset: {train_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "print(f\"Validation dataset: {val_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "print(f\"Test dataset: {test_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "\n",
    "print(\"dataset load complete.\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 1)\n",
    "\n",
    "model.load_state_dict(torch.load('VGG16_best_model_weights.pth'))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "model = model.cuda()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"model initialization.\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
    "    best_auc = 0.0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for inputs, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            train_preds.append(outputs.detach().cpu().numpy())\n",
    "            train_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "        train_labels = np.concatenate(train_labels)\n",
    "        train_auc = roc_auc_score(train_labels, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda().float().unsqueeze(1)\n",
    "                outputs = model(inputs)\n",
    "                val_preds.append(outputs.cpu().numpy())\n",
    "                val_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train AUC: {train_auc:.3f}, Val AUC: {val_auc:.3f}')\n",
    "        torch.save(model.module.state_dict(), 'VGG16_model_weights.pth')\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_model_wts = model.module.state_dict()  # Save the model.module state_dict for DataParallel\n",
    "\n",
    "    model.module.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, best_auc\n",
    "\n",
    "# Train the model\n",
    "model, best_val_auc = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
    "print(f'Best Val AUC: {best_val_auc:.3f}')\n",
    "\n",
    "# Save the best model weights\n",
    "torch.save(model.module.state_dict(), 'VGG16_best_model_weights.pth')\n",
    "\n",
    "# Plot ROC curves\n",
    "def plot_roc_curve(loader, model, dataset_type):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic ({dataset_type} Set)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "# Plot ROC curve for train set\n",
    "train_auc = plot_roc_curve(train_loader, model, 'Train')\n",
    "print(f'Train AUC: {train_auc:.3f}')\n",
    "\n",
    "# Plot ROC curve for validation set\n",
    "val_auc = plot_roc_curve(val_loader, model, 'Validation')\n",
    "print(f'Validation AUC: {val_auc:.3f}')\n",
    "\n",
    "# Load the best model weights for testing\n",
    "model.module.load_state_dict(torch.load('VGG16_best_model_weights.pth'))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_auc = plot_roc_curve(test_loader, model, 'Test')\n",
    "print(f'Test AUC: {test_auc:.3f}')\n",
    "\n",
    "# Calculate additional metrics for the test set\n",
    "def evaluate_metrics(loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    preds_binary = (all_preds >= threshold).astype(int)\n",
    "\n",
    "    tp = (preds_binary * all_labels).sum()\n",
    "    tn = ((1 - preds_binary) * (1 - all_labels)).sum()\n",
    "    fp = (preds_binary * (1 - all_labels)).sum()\n",
    "    fn = ((1 - preds_binary) * all_labels).sum()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "\n",
    "    return sensitivity, specificity, accuracy, ppv, npv\n",
    "\n",
    "sensitivity, specificity, accuracy, ppv, npv = evaluate_metrics(test_loader, model)\n",
    "\n",
    "print(f'Test Set Metrics:')\n",
    "print(f'Sensitivity: {sensitivity:.3f}')\n",
    "print(f'Specificity: {specificity:.3f}')\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'PPV: {ppv:.3f}')\n",
    "print(f'NPV: {npv:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing (RSNA dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision.models import VGG16_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Plot ROC curves\n",
    "def plot_roc_curve(loader, model, dataset_type):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic ({dataset_type} Set)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "class PulmonaryEmbolismDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, window_center, window_width, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.window_center = window_center\n",
    "        self.window_width = window_width\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_uid = self.data_frame.iloc[idx]['StudyInstanceUID']\n",
    "        series_uid = self.data_frame.iloc[idx]['SeriesInstanceUID']\n",
    "        sop_uid = self.data_frame.iloc[idx]['SOPInstanceUID']\n",
    "        file_path = os.path.join(self.root_dir, study_uid, series_uid, f\"{sop_uid}.dcm\")\n",
    "        dicom_image, _ = self.load_and_process_dicom(file_path)\n",
    "        if self.transform:\n",
    "            dicom_image = self.transform(dicom_image)\n",
    "        label = self.data_frame.iloc[idx]['pe_present_on_image']\n",
    "        return dicom_image, label, file_path\n",
    "\n",
    "    def load_and_process_dicom(self, dicom_file):\n",
    "        ds = pydicom.dcmread(dicom_file)\n",
    "        image = ds.pixel_array\n",
    "        if \"RescaleIntercept\" in ds and \"RescaleSlope\" in ds:\n",
    "            intercept = ds.RescaleIntercept\n",
    "            slope = ds.RescaleSlope\n",
    "            hu_image = self.convert_to_hounsfield_units(image, intercept, slope)\n",
    "        else:\n",
    "            hu_image = image.astype(np.int16)\n",
    "        windowed_image = self.apply_windowing_correctly(hu_image, self.window_center, self.window_width)\n",
    "        resized_image = Image.fromarray(windowed_image).resize((224, 224))\n",
    "        image_tensor = torch.tensor(np.array(resized_image), dtype=torch.float32).unsqueeze(0)\n",
    "        image_tensor = image_tensor.repeat(3, 1, 1)  # 3 채널로 복사\n",
    "        image_tensor = image_tensor / 255.0  # 0~1 범위로 정규화\n",
    "        return image_tensor, hu_image\n",
    "\n",
    "    def apply_windowing_correctly(self, image, window_center, window_width):\n",
    "        window_min = window_center - window_width / 2\n",
    "        window_max = window_center + window_width / 2\n",
    "        windowed_image = np.clip(image, window_min, window_max)\n",
    "        return ((windowed_image - window_min) / (window_max - window_min) * 255).astype(np.uint8)\n",
    "\n",
    "    def convert_to_hounsfield_units(self, image, intercept, slope):\n",
    "        return image * slope + intercept\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([])  # No transformation\n",
    "\n",
    "# Load the dataset\n",
    "csv_file = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/RSNA dataset/rsna-str-pulmonary-embolism-detection/train_processed.csv'\n",
    "root_dir = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/RSNA dataset/rsna-str-pulmonary-embolism-detection/train'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Sample the dataset\n",
    "sampled_df = df.groupby('StudyInstanceUID').apply(lambda x: x.sample(frac=0.1, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Split the sampled dataset by StudyInstanceUID to avoid data leakage\n",
    "unique_studies = sampled_df['StudyInstanceUID'].unique()\n",
    "train_studies, temp_studies = train_test_split(unique_studies, test_size=0.2, random_state=42)\n",
    "val_studies, test_studies = train_test_split(temp_studies, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = sampled_df[sampled_df['StudyInstanceUID'].isin(train_studies)].reset_index(drop=True)\n",
    "val_df = sampled_df[sampled_df['StudyInstanceUID'].isin(val_studies)].reset_index(drop=True)\n",
    "test_df = sampled_df[sampled_df['StudyInstanceUID'].isin(test_studies)].reset_index(drop=True)\n",
    "\n",
    "# Create the datasets\n",
    "test_dataset = PulmonaryEmbolismDataset(test_df, root_dir, window_center=40, window_width=400, transform=transform)\n",
    "test_pe_label_percent = (test_df['pe_present_on_image'].mean()) * 100\n",
    "print(f\"Test dataset: {test_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "\n",
    "\n",
    "print(\"dataset load complete.\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 2048\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 1)\n",
    "\n",
    "model.load_state_dict(torch.load('VGG16_best_model_weights.pth'))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "model = model.cuda()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_auc = plot_roc_curve(test_loader, model, 'Test')\n",
    "print(f'Test AUC: {test_auc:.3f}')\n",
    "\n",
    "# Calculate additional metrics for the test set\n",
    "def evaluate_metrics(loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    preds_binary = (all_preds >= threshold).astype(int)\n",
    "\n",
    "    tp = (preds_binary * all_labels).sum()\n",
    "    tn = ((1 - preds_binary) * (1 - all_labels)).sum()\n",
    "    fp = (preds_binary * (1 - all_labels)).sum()\n",
    "    fn = ((1 - preds_binary) * all_labels).sum()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "\n",
    "    return sensitivity, specificity, accuracy, ppv, npv\n",
    "\n",
    "sensitivity, specificity, accuracy, ppv, npv = evaluate_metrics(test_loader, model)\n",
    "\n",
    "print(f'Test Set Metrics:')\n",
    "print(f'Sensitivity: {sensitivity:.3f}')\n",
    "print(f'Specificity: {specificity:.3f}')\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'PPV: {ppv:.3f}')\n",
    "print(f'NPV: {npv:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference in external validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL CONTRAST KNU EXTERNAL N=62 \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "# Random seed 설정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Plot ROC curves\n",
    "def plot_roc_curve(loader, model, dataset_type):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic ({dataset_type} Set)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('TEST IN KNU FULL APPEND (REAL CONTRAST)', format='eps', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "class PulmonaryEmbolismDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_uid = self.data_frame.iloc[idx]['StudyInstanceUID']\n",
    "        series_uid = self.data_frame.iloc[idx]['SeriesInstanceUID']\n",
    "        sop_uid = str(self.data_frame.iloc[idx]['SOPInstanceUID']).zfill(4)  # Ensure SOPInstanceUID is a 4-digit string\n",
    "        file_path = os.path.join(self.root_dir, study_uid, series_uid, f\"{sop_uid}.jpg\")\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data_frame.iloc[idx]['pe_present_on_image']\n",
    "        return image, label, file_path\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "csv_file = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/output with pe label (GAN lc, 0.5)_KNU_append+KNUnormal.csv'\n",
    "root_dir = '/workspace/kyt3426/project_chest_CT_GAN/external_data_jpg_KNUnormal_and_append'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Create the datasets using the entire dataframe for external validation\n",
    "test_dataset = PulmonaryEmbolismDataset(df, root_dir, transform=transform)\n",
    "test_pe_label_percent = (df['pe_present_on_image'].mean()) * 100\n",
    "print(f\"Test dataset: {test_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "\n",
    "# Print additional statistics\n",
    "num_slices = len(df)\n",
    "num_slices_pe_0 = len(df[df['pe_present_on_image'] == 0])\n",
    "num_slices_pe_1 = len(df[df['pe_present_on_image'] == 1])\n",
    "num_unique_patients = df['StudyInstanceUID'].nunique()\n",
    "\n",
    "print(f\"Total number of slices: {num_slices}\")\n",
    "print(f\"Number of slices with label 0: {num_slices_pe_0}\")\n",
    "print(f\"Number of slices with label 1: {num_slices_pe_1}\")\n",
    "print(f\"Number of patients: {num_unique_patients}\")\n",
    "\n",
    "print(\"Dataset load complete.\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 256\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 1)\n",
    "\n",
    "model.load_state_dict(torch.load('VGG16_best_model_weights.pth'))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "model = model.cuda()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_auc = plot_roc_curve(test_loader, model, 'Test')\n",
    "print(f'Test AUC: {test_auc:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN CONTRAST KNU EXTERNAL N=62\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "# Random seed 설정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Plot ROC curves\n",
    "def plot_roc_curve(loader, model, dataset_type):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic ({dataset_type} Set)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('TEST IN KNU FULL APPEND (GAN CONTRAST)', format='eps', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "class PulmonaryEmbolismDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_uid = self.data_frame.iloc[idx]['StudyInstanceUID']\n",
    "        series_uid = self.data_frame.iloc[idx]['SeriesInstanceUID']\n",
    "        sop_uid = str(self.data_frame.iloc[idx]['SOPInstanceUID']).zfill(4)  # Ensure SOPInstanceUID is a 4-digit string\n",
    "        file_path = os.path.join(self.root_dir, study_uid, series_uid, f\"{sop_uid}.jpg\")\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data_frame.iloc[idx]['pe_present_on_image']\n",
    "        return image, label, file_path\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "csv_file = '/workspace/kyt3426/project_chest_CT_GAN/Embolism_classification_(RSNA_dataset)/output with pe label (GAN lc, 0.5)_KNU_append+KNUnormal.csv'\n",
    "root_dir = '/workspace/kyt3426/project_chest_CT_GAN/Inference_test_based_on_dualCT_model_only_disease_lc0.5_KNU_EXTERNAL'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Create the datasets using the entire dataframe for external validation\n",
    "test_dataset = PulmonaryEmbolismDataset(df, root_dir, transform=transform)\n",
    "test_pe_label_percent = (df['pe_present_on_image'].mean()) * 100\n",
    "print(f\"Test dataset: {test_pe_label_percent:.2f}% of samples have pe_label=1\")\n",
    "\n",
    "# Print additional statistics\n",
    "num_slices = len(df)\n",
    "num_slices_pe_0 = len(df[df['pe_present_on_image'] == 0])\n",
    "num_slices_pe_1 = len(df[df['pe_present_on_image'] == 1])\n",
    "num_unique_patients = df['StudyInstanceUID'].nunique()\n",
    "\n",
    "print(f\"Total number of slices: {num_slices}\")\n",
    "print(f\"Number of slices with label 0: {num_slices_pe_0}\")\n",
    "print(f\"Number of slices with label 1: {num_slices_pe_1}\")\n",
    "print(f\"Number of patients: {num_unique_patients}\")\n",
    "\n",
    "print(\"Dataset load complete.\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 256\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 1)\n",
    "\n",
    "model.load_state_dict(torch.load('VGG16_best_model_weights.pth'))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "model = model.cuda()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_auc = plot_roc_curve(test_loader, model, 'Test')\n",
    "print(f'Test AUC: {test_auc:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
